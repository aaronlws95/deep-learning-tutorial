{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khZPedMTJBIJ"
   },
   "source": [
    "# __Part 1: PyTorch Basics__\n",
    "\n",
    "PyTorch is an open source machine learning library based on the [Torch](http://torch.ch/) library. It is primarily developed by [Facebook's AI Research lab (FAIR)](https://ai.facebook.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "\n",
    "This tutorial assumes you already have some basic knowledge of programming with [Python](https://www.python.org/). If not there are loads of Python tutorials available online. I just did a quick Google search and found [this](https://www.tutorialspoint.com/python/index.htm) and [this](https://www.learnpython.org/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljEkM1-xoW00"
   },
   "source": [
    "# Setup\n",
    "\n",
    "It is recommended to run this notebook in [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true). You can also run this notebook on your machine by [installing PyTorch](https://pytorch.org/get-started/locally/) locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "rIgX1yZAhaeK",
    "outputId": "c8dd641a-e3e1-46a9-8aec-e8b2614cf2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 15:18:16) [MSC v.1916 64 bit (AMD64)]\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "print(sys.version)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHwf0wYajPJe"
   },
   "source": [
    "# Tensors\n",
    "\n",
    "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "fRiBEVCgjG6k",
    "outputId": "824a6c97-eea0-4920-ceba-4cc74363c4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7980e-09, 6.3619e-43, 2.7980e-09],\n",
      "        [6.3619e-43, 2.7981e-09, 6.3619e-43],\n",
      "        [2.7981e-09, 6.3619e-43, 2.7978e-09],\n",
      "        [6.3619e-43, 2.7978e-09, 6.3619e-43],\n",
      "        [2.7983e-09, 6.3619e-43, 2.7983e-09]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a 5x3 matrix, uninitialized\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "wxYSuud9kpN6",
    "outputId": "0529d278-f474-4414-86b6-273b054d7e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5170, 0.6947, 0.6664],\n",
      "        [0.2518, 0.7912, 0.3462],\n",
      "        [0.2508, 0.4258, 0.7869],\n",
      "        [0.3101, 0.5825, 0.6662],\n",
      "        [0.7112, 0.2578, 0.9234]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a 5x3 matrix, randomly initialized\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "J7pPj7-Ckdep",
    "outputId": "c105fc4d-fb7b-469d-cb09-7bc3d146ea34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a 5x3 matrix, initialized with zero\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ZjELC8-3k0z2",
    "outputId": "1fff19de-89ee-4c64-e773-8afcc7066259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.5000, 3.0000],\n",
      "        [0.1000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a 2x2 matrix, initialized with custom values\n",
    "x = torch.tensor([[5.5, 3], [0.1, 1]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8715rPzldVd"
   },
   "source": [
    "# Operators\n",
    "\n",
    "You can find the list of all operations described [here](https://pytorch.org/docs/stable/torch.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "1iaIke9jk_h0",
    "outputId": "d850c70f-762a-435c-c7ac-b04dd5cda69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.3047, 0.8861],\n",
      "        [0.3961, 0.5160]])\n",
      "tensor([[1.3047, 1.8861],\n",
      "        [1.3961, 1.5160]])\n",
      "tensor([[0.6953, 0.1139],\n",
      "        [0.6039, 0.4840]])\n",
      "tensor([[0.3047, 0.8861],\n",
      "        [0.3961, 0.5160]])\n",
      "tensor([[0.7008, 1.4021],\n",
      "        [0.7008, 1.4021]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# Addition\n",
    "print(x + y) # alternatively, print(torch.add(x, y)) \n",
    "\n",
    "# Subtraction\n",
    "print(x - y) # alternatively, print(torch.sub(x, y))\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(x * y) # alternatively, print(torch.mul(x, y)) \n",
    "\n",
    "# Matrix multiplication\n",
    "print(torch.mm(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmlsNDgInamx"
   },
   "source": [
    "# Tensors ⇄ Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zED5o_ZNn0fx",
    "outputId": "1dc15be2-b249-43c2-d539-a2ced7d08dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "78CRwGPinZgx",
    "outputId": "24b4fffe-968a-4b84-dee6-48a9ff0c1d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Torch tensor to NumPy array\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ptTrH1gXmUS9",
    "outputId": "21e448e2-e224-4fca-a760-5e355b73321a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# NumPy array to torch tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h3IxkKRBohfq"
   },
   "source": [
    "# CUDA Tensors\n",
    "\n",
    "[CUDA](https://en.wikipedia.org/wiki/CUDA) is a parallel computing platform and application programming interface (API) model created by [Nvidia](https://www.nvidia.com/en-us/location-selector/). It is used to allow computing on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "b0R9c49TpA40",
    "outputId": "90afc984-a0c8-4295-b66c-1ca4c11e40d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available?: True\n",
      "How many GPUs?: 1\n",
      "Which id GPU is currently being used?: 0\n",
      "What model GPU is currently being used?: GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "print('Is GPU available?:', torch.cuda.is_available())\n",
    "print('How many GPUs?:', torch.cuda.device_count())\n",
    "print('Which id GPU is currently being used?:', torch.cuda.current_device())\n",
    "print('What model GPU is currently being used?:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "FovlH3KUn8IF",
    "outputId": "793a1b98-ca1b-44fc-e0aa-c266382d72dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")        # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z.is_cuda)                       # check if variable is on the GPU \n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "b20sNeYUGihg",
    "outputId": "d6763fcd-5db2-44b3-8d35-82432a715ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Move tensor out of GPU to CPU\n",
    "print(z.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9C2EbU-SUJe7"
   },
   "source": [
    "# Autograd: Automatic differentiation\n",
    "\n",
    "The autograd package provides automatic differentiation for all operations on Tensors. The system is based on tape-based automatic differentiation. A recorder records what operations have been performed, and then it replays it backward to compute the gradients. It is a define-by-run framework, which means that your backpropagation is defined by how your code is run, and that every single iteration can be different. More details if you are interested [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "1NuohNAEUKk4",
    "outputId": "db57c537-e580-4b9b-8f13-f97d9a33c1da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors and set requires_grad=True to track computation with it\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph\n",
    "y = w * x + b \n",
    "\n",
    "# Compute the gradients\n",
    "y.backward()\n",
    "\n",
    "# Calculate the gradients\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O9Owc5TjUM0N",
    "outputId": "be4eec40-d383-401d-dc72-733bf035f722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.0000, 12.0000,  1.6000])\n"
     ]
    }
   ],
   "source": [
    "# Create a non-scalar tensor\n",
    "x = torch.tensor([2., 3., 4.], requires_grad=True)\n",
    "\n",
    "# Build a computational graph\n",
    "y = x * x * 2\n",
    "\n",
    "# Specify gradient argument\n",
    "v = torch.tensor([1., 1., 0.1])\n",
    "\n",
    "# Compute gradients\n",
    "y.backward(v)\n",
    "\n",
    "# Calculate the gradients\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "gjCFbd6PUOyM",
    "outputId": "907e02e1-c75c-49a5-8a53-91e098cadd3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires grad?: True\n",
      "Requires grad?: True\n",
      "Requires grad?: False\n",
      "Requires grad?: False\n"
     ]
    }
   ],
   "source": [
    "# Check if we are tracking computation\n",
    "x = torch.tensor(3., requires_grad=True)\n",
    "print('Requires grad?:', x.requires_grad)\n",
    "print('Requires grad?:', (x**2).requires_grad)\n",
    "\n",
    "# Stop autograd from tracking history on Tensors \n",
    "with torch.no_grad():\n",
    "  print('Requires grad?:', (x**2).requires_grad)\n",
    "\n",
    "# Use detach to remove from computation history\n",
    "print('Requires grad?:', x.detach().requires_grad)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
