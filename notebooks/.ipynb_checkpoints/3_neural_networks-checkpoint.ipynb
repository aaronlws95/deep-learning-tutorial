{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NbD6wN2jsNQk"
   },
   "source": [
    "# Neural Networks\n",
    "\n",
    "In this example, we introduce neural networks for classifying images of cats and dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWy1TeXaugg5"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uInhSQxQ2j0q"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wToffUGKsKUK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZz0qkjP6gxI"
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "NUM_WORKERS = 2\n",
    "DATA_DIR_EXTENSION = 'D:/datasets/'\n",
    "DATA_DIR = DATA_DIR_EXTENSION + 'Cat_Dog_data'  # set data path to ``Cat_Dog_data``\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "RESIZE = 32 # Modify image dimensions to 3 x RESIZE x RESIZE\n",
    "NUM_EPOCH = 5\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o260Uym4ul0T"
   },
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "-k-iK-vGyD4Q",
    "outputId": "ef97b42f-a45c-4aa0-949d-8a3cb924f5f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download Cat_Dog dataset\n",
    "!wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
    "\n",
    "# Path to training data: ``Cat_Dog_data/train``\n",
    "# Path to testing data: ``Cat_Dog_data/test``\n",
    "!unzip -qq Cat_Dog_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "rbMIwX-w6KRi",
    "outputId": "a1250fce-f0cf-4d00-b908-7908f23ebc14"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Cat_Dog_data/train/cat/cat.0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9aaac651a67a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Show an example image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexample_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/train/cat/cat.0.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Cat_Dog_data/train/cat/cat.0.jpg'"
     ]
    }
   ],
   "source": [
    "# Show an example image\n",
    "example_img = Image.open(DATA_DIR + '/train/cat/cat.0.jpg')\n",
    "plt.imshow(example_img)\n",
    "plt.show()\n",
    "\n",
    "# PIL image to NumPy array\n",
    "numpy_img = np.array(example_img)\n",
    "print(numpy_img.shape) # (Height, Width, Channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxQpv3WksrNw"
   },
   "outputs": [],
   "source": [
    "# Transform to preprocess images\n",
    "# 1. Resize image to the same height and width\n",
    "# 2. Convert image (H x W x C) in range [0, 255] to torch tensor (C x H x W) in \n",
    "# the range [0.0, 1.0]\n",
    "transform = transforms.Compose([transforms.Resize((RESIZE, RESIZE)),\n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "# Create training dataloader\n",
    "train_set = torchvision.datasets.ImageFolder(root=DATA_DIR + '/train', \n",
    "                                             transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=NUM_WORKERS)\n",
    "\n",
    "# Create testing dataloader\n",
    "test_set = torchvision.datasets.ImageFolder(root=DATA_DIR + '/test', \n",
    "                                        transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, \n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, \n",
    "                                          num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Ptid4iTYt_vQ",
    "outputId": "124f0846-a646-462f-e51e-71654f1b6738"
   },
   "outputs": [],
   "source": [
    "print('Number of training samples:', len(train_set))\n",
    "print('Number of testing samples:', len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "41ihMnq0uK6L",
    "outputId": "0a94b4a7-51fb-4231-80a2-c0b217efe9d7"
   },
   "outputs": [],
   "source": [
    "# Load one data batch\n",
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "# Print image shape\n",
    "print('Shape:', inputs[0].shape)\n",
    "\n",
    "# Visualize the data batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "plt.imshow(out.permute(1, 2, 0))\n",
    "plt.title('Classes: ' + str(classes.numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "269Heg7j-uT3"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1wM567f-tyA"
   },
   "outputs": [],
   "source": [
    "# Two layer linear neural network\n",
    "class LinearNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(RESIZE*RESIZE*3, (RESIZE*RESIZE*3)//2)\n",
    "        self.fc2 = nn.Linear((RESIZE*RESIZE*3)//2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(BATCH_SIZE, -1)  # flatten image into a vector\n",
    "        x = self.fc1(x)             \n",
    "        x = self.fc2(x)\n",
    "        x = nn.Sigmoid()(x)         # sigmoid layer\n",
    "        x = x.squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhwWxbGOITov"
   },
   "outputs": [],
   "source": [
    "# Simple convolutional net\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 3 input channel, 6 output channels, 3x3 convolution kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=1)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * RESIZE//4 * RESIZE//4, 120)  \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(BATCH_SIZE, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = x.squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDr8WvlgBXrW"
   },
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "\n",
    "# Send model to GPU\n",
    "net = net.cuda() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7q4gXYbAsPQ"
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6kWSti-udDG"
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwrAAwTwFvJk"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYeijXFQFvnk"
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsLOQId4BH9s"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "PmMJHpU3BHhZ",
    "outputId": "ecdcdcc2-9109-46db-b3ff-3918e2524ee4"
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCH):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0): # learn from 1 batch\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        labels = labels.type(torch.FloatTensor) # cast labels to float\n",
    "\n",
    "        # Send data to GPU\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('Epoch: %d | Batch: %5d | Loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HNrI59FFoFr"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aaNw6MioBxRI",
    "outputId": "e15d47ca-58f6-4514-99ce-9bbe90f29c25"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Switch network to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad(): # we don't need gradients for evaluation\n",
    "    for data in test_loader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        images, labels = data\n",
    "\n",
    "        # Send data to GPU\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        # Get prediction\n",
    "        outputs = net(images)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        \n",
    "        # Accumulate statistics\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LFyDzHLCHBTn",
    "outputId": "834fba21-05a7-4ce7-e829-4f0d1e800fc7"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Switch network to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad(): # we don't need gradients for evaluation\n",
    "    for data in train_loader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        images, labels = data\n",
    "\n",
    "        # Send data to GPU\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        # Get prediction\n",
    "        outputs = net(images)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        \n",
    "        # Accumulate statistics\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "e8kbZdkLWwvk",
    "outputId": "268568e0-0ba5-4c9c-a135-401ca8823699"
   },
   "outputs": [],
   "source": [
    "classes = ('cat', 'dog')\n",
    "class_correct = list(0. for i in range(NUM_CLASSES))\n",
    "class_total = list(0. for i in range(NUM_CLASSES))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(images)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(BATCH_SIZE):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cu3TqG1AgN8r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "binary_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
